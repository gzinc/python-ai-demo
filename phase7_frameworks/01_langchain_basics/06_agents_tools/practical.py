"""
Agents & Tools - Practical Demonstrations (LangChain 1.0+ / LangGraph)

This module provides hands-on examples of LangChain agents and tools using
the modern LangGraph API (LangChain 1.0+).

Requires OPENAI_API_KEY in .env file.

Run with: uv run python -m phase7_frameworks.01_langchain_basics.06_agents_tools.practical
"""

from datetime import datetime
from inspect import cleandoc

from dotenv import load_dotenv
from simpleeval import simple_eval
from langchain.agents import create_agent
from langchain.tools import BaseTool, tool
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from pydantic import Field

from common.demo_menu import Demo, MenuRunner
from common.util.utils import print_section, check_api_keys

# load environment variables
load_dotenv()



# region Demo 1: Basic Tool Creation


def demo_basic_tool_creation() -> None:
    """
    demonstrate basic tool creation with @tool decorator

    Basic Tool Creation Pattern:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         @tool Decorator: Simple Function â†’ LangChain Tool   â”‚
    â”‚                                                             â”‚
    â”‚  Python Function:                                           â”‚
    â”‚     def calculator(expression: str) -> float:               â”‚
    â”‚         '''evaluate math expressions'''                     â”‚
    â”‚         return eval(expression)                             â”‚
    â”‚                                                             â”‚
    â”‚  Decorator Application:                                     â”‚
    â”‚     @tool                                                   â”‚
    â”‚     def calculator(expression: str) -> float:               â”‚
    â”‚         '''evaluate mathematical expressions'''             â”‚
    â”‚         return eval(expression)                             â”‚
    â”‚         â†“                                                   â”‚
    â”‚     Automatic Extraction:                                   â”‚
    â”‚       â€¢ name: "calculator" (from function name)             â”‚
    â”‚       â€¢ description: "evaluate mathematical expressions"    â”‚
    â”‚       â€¢ args_schema: {"expression": str} (from signature)   â”‚
    â”‚                                                             â”‚
    â”‚  Usage in Agent (LangGraph):                                â”‚
    â”‚     tools = [calculator]                                    â”‚
    â”‚     agent = create_agent(model=llm, tools=tools)            â”‚
    â”‚         â”‚                                                   â”‚
    â”‚         â–¼                                                   â”‚
    â”‚     Agent can now use calculator tool automatically!        â”‚
    â”‚                                                             â”‚
    â”‚  Tool Execution Flow:                                       â”‚
    â”‚     User Query â†’ Agent â†’ Tool Selection â†’ Tool Execution    â”‚
    â”‚                    â†“                          â†“             â”‚
    â”‚                  "2+2"                   calculator("2+2")  â”‚
    â”‚                    â†“                          â†“             â”‚
    â”‚                Final Answer  â†  Tool Result (4.0)           â”‚
    â”‚                                                             â”‚
    â”‚  âœ… Benefit: Zero boilerplate (decorator handles metadata)  â”‚
    â”‚  âœ… Benefit: Type hints â†’ automatic schema validation       â”‚
    â”‚  âœ… Security: simple_eval() for safe math (no code exec)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    print_section("Demo 1: Basic Tool Creation with @tool")

    # define calculator tool
    @tool
    def calculator(expression: str) -> str:
        """evaluate mathematical expressions like '2+2' or '25*48+100'"""
        print(f"  ðŸ”§ tool used: calculator(expression='{expression}')")
        try:
            # safe evaluation: only allows math operations, no code execution
            result = simple_eval(expression)
            return str(float(result))
        except Exception as e:
            return f"Error: {str(e)}"

    print("1. Tool created with @tool decorator")
    print("\n2. Tool metadata (automatically extracted):")
    print(f"   â€¢ name: {calculator.name}")
    print(f"   â€¢ description: {calculator.description}")
    print(f"   â€¢ args: {list(calculator.args_schema.model_fields.keys())}")

    print("\n3. Direct tool execution (without agent):")
    result = calculator.invoke({"expression": "2 + 2"})
    print(f"   calculator('2 + 2') = {result}")

    print("\n4. How @tool works:")
    print("   â€¢ Function name â†’ tool name")
    print("   â€¢ Docstring â†’ tool description")
    print("   â€¢ Type hints â†’ argument schema")


# endregion


# region Demo 2: Creating Agent with Tools


def demo_create_agent() -> None:
    """
    demonstrate create_agent basics with single tool (ReAct pattern)

    ReAct Agent Creation Pattern (LangChain 1.0+ / LangGraph):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     create_agent: Model + Tools â†’ CompiledGraph             â”‚
    â”‚                                                             â”‚
    â”‚  Step 1: Define Tools                                       â”‚
    â”‚     @tool                                                   â”‚
    â”‚     def get_time() -> str:                                  â”‚
    â”‚         ""get current time""                                â”‚
    â”‚         return datetime.now().strftime("%H:%M")             â”‚
    â”‚                                                             â”‚
    â”‚  Step 2: Create Agent (LangGraph simplified API)            â”‚
    â”‚     agent = create_agent(                                   â”‚
    â”‚         model=ChatOpenAI(model="gpt-4o-mini"),              â”‚
    â”‚         tools=[get_time]                                    â”‚
    â”‚     )                                                       â”‚
    â”‚     # Returns CompiledStateGraph, ready to use!             â”‚
    â”‚                                                             â”‚
    â”‚  Step 3: Execute Query                                      â”‚
    â”‚     result = agent.invoke({                                 â”‚
    â”‚         "messages": [HumanMessage(content="What time?")]    â”‚
    â”‚     })                                                      â”‚
    â”‚         â–¼                                                   â”‚
    â”‚     Agent ReAct Loop:                                       â”‚
    â”‚       Thought: "I need the current time"                    â”‚
    â”‚       Action: get_time()                                    â”‚
    â”‚       Observation: "14:30"                                  â”‚
    â”‚       Thought: "I have the answer"                          â”‚
    â”‚       Final Answer: "It is 14:30"                           â”‚
    â”‚                                                             â”‚
    â”‚  Tool â†’ Agent â†’ LLM â†’ Tool â†’ Agent â†’ Answer                 â”‚
    â”‚                                                             â”‚
    â”‚  âœ… Benefit: Simpler API (no AgentExecutor needed)          â”‚
    â”‚  âœ… Benefit: LLM decides when to use tools                  â”‚
    â”‚  âœ… Benefit: Built-in streaming and async support           â”‚
    â”‚  âš ï¸  Caution: LLM calls cost money (watch iterations)       â”‚
    â”‚                                                             â”‚
    â”‚  â„¹ï¸  Note: LangChain 1.0+ uses LangGraph for agents         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    print_section("Demo 2: create_agent Basics - ReAct Pattern (LangChain 1.0+)")

    # define time tool
    @tool
    def get_current_time() -> str:
        """get the current time in HH:MM format"""
        print("  ðŸ”§ tool used: get_current_time()")
        return datetime.now().strftime("%H:%M")

    print("1. Tool metadata (automatically extracted):")
    print(f"   â€¢ name: {get_current_time.name}")
    print(f"   â€¢ description: {get_current_time.description}")

    # create llm and tools
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    tools = [get_current_time]

    # create agent (LangGraph simplified API)
    agent = create_agent(model=llm, tools=tools)

    print("\n2. Agent created (CompiledStateGraph)")
    print(f"   Type: {type(agent).__name__}")

    print("\n3. Asking agent: 'What time is it?'")
    print("   (Agent will use ReAct pattern to answer)")

    # invoke with messages format
    result = agent.invoke({"messages": [HumanMessage(content="What time is it?")]})

    # extract final answer from messages
    final_message = result["messages"][-1]
    print(f"\n4. Agent result: {final_message.content}")

    print("\n5. ReAct pattern flow:")
    print("   Thought â†’ Action â†’ Observation â†’ Thought â†’ Answer")

    print("\n6. LangChain 1.0+ / LangGraph simplifications:")
    print("   â€¢ No AgentExecutor needed")
    print("   â€¢ Direct invoke() on agent")
    print("   â€¢ Messages-based interface")
    print("   â€¢ Built-in tool calling")


# endregion


# region Demo 3: Multi-Tool Agent


def demo_multi_tool_agent() -> None:
    """
    demonstrate agent with multiple tools

    Multi-Tool Agent Pattern:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            Agent with Multiple Tool Options                 â”‚
    â”‚                                                             â”‚
    â”‚  Tools Available:                                           â”‚
    â”‚     1. calculator(expression: str) â†’ float                  â”‚
    â”‚     2. string_reverse(text: str) â†’ str                      â”‚
    â”‚     3. string_upper(text: str) â†’ str                        â”‚
    â”‚                                                             â”‚
    â”‚  Agent Decision Making:                                     â”‚
    â”‚     User: "What is 25 * 48 + 100?"                          â”‚
    â”‚       â†“                                                     â”‚
    â”‚     Agent analyzes query â†’ identifies math task             â”‚
    â”‚       â†“                                                     â”‚
    â”‚     Selects calculator tool (not string tools)              â”‚
    â”‚       â†“                                                     â”‚
    â”‚     Executes: calculator("25*48+100")                       â”‚
    â”‚       â†“                                                     â”‚
    â”‚     Returns: 1300.0                                         â”‚
    â”‚                                                             â”‚
    â”‚  Tool Selection Criteria:                                   â”‚
    â”‚     â€¢ Tool name relevance                                   â”‚
    â”‚     â€¢ Tool description match                                â”‚
    â”‚     â€¢ Query context analysis                                â”‚
    â”‚     â€¢ Previous interaction history                          â”‚
    â”‚                                                             â”‚
    â”‚  âœ… Benefit: Agent chooses appropriate tool                 â”‚
    â”‚  âœ… Benefit: Multiple capabilities in one agent             â”‚
    â”‚  âœ… Benefit: Extensible (add more tools easily)             â”‚
    â”‚  âš ï¸  Caution: Too many tools can confuse the agent          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    print_section("Demo 3: Multi-Tool Agent")

    # define multiple tools
    @tool
    def calculator(expression: str) -> str:
        """evaluate mathematical expressions"""
        print(f"  ðŸ”§ tool used: calculator(expression='{expression}')")
        try:
            # safe evaluation: only allows math operations, no code execution
            return str(float(simple_eval(expression)))
        except Exception as e:
            return f"Error: {str(e)}"

    @tool
    def string_reverse(text: str) -> str:
        """reverse a string"""
        print(f"  ðŸ”§ tool used: string_reverse(text='{text}')")
        return text[::-1]

    @tool
    def string_upper(text: str) -> str:
        """convert string to uppercase"""
        print(f"  ðŸ”§ tool used: string_upper(text='{text}')")
        return text.upper()

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    tools = [calculator, string_reverse, string_upper]

    agent = create_agent(model=llm, tools=tools)

    print("\n1. Agent has 3 tools:")
    for t in tools:
        print(f"   â€¢ {t.name}: {t.description}")

    # test different queries
    test_queries = [
        "What is 25 * 48 + 100?",
        "Reverse the string 'hello'",
        "Convert 'python' to uppercase",
    ]

    for i, query in enumerate(test_queries, 1):
        print(f"\n{i+1}. Query: {query}")
        result = agent.invoke({"messages": [HumanMessage(content=query)]})
        final_answer = result["messages"][-1].content
        print(f"   Answer: {final_answer}")

    print("\n5. Tool selection insights:")
    print("   â€¢ Agent analyzes query semantics")
    print("   â€¢ Matches query to tool description")
    print("   â€¢ Executes most relevant tool")


# endregion


# region Demo 4: Custom Tool Class


def demo_custom_tool_class() -> None:
    """
    demonstrate custom tool using BaseTool class

    Custom Tool Class Pattern:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         BaseTool: Stateful Tools with Advanced Features     â”‚
    â”‚                                                             â”‚
    â”‚  @tool Decorator (Simple):                                  â”‚
    â”‚     @tool                                                   â”‚
    â”‚     def search(query: str) -> str:                          â”‚
    â”‚         return api_call(query)                              â”‚
    â”‚                                                             â”‚
    â”‚  âœ… Good for: Stateless functions                           â”‚
    â”‚  âŒ Limitations: No state, no complex initialization        â”‚
    â”‚                                                             â”‚
    â”‚  BaseTool Class (Advanced):                                 â”‚
    â”‚     class WeatherTool(BaseTool):                            â”‚
    â”‚         name: str = "weather"                               â”‚
    â”‚         description: str = "get weather"                    â”‚
    â”‚         api_key: str = Field(...)  # state!                 â”‚
    â”‚                                                             â”‚
    â”‚         def _run(self, city: str) -> str:                   â”‚
    â”‚             # use self.api_key                              â”‚
    â”‚             return fetch_weather(city, self.api_key)        â”‚
    â”‚                                                             â”‚
    â”‚  âœ… Good for: Stateful tools, API clients, DB connections   â”‚
    â”‚  âœ… Good for: Async support, error handling, retries        â”‚
    â”‚  âœ… Good for: Complex initialization logic                  â”‚
    â”‚                                                             â”‚
    â”‚  When to use each:                                          â”‚
    â”‚     @tool â†’ Simple stateless functions                      â”‚
    â”‚     BaseTool â†’ Stateful tools with configuration            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    print_section("Demo 4: Custom Tool Class with BaseTool")

    # define custom tool class
    class WeatherTool(BaseTool):
        name: str = "weather"
        description: str = "get current weather for a city. useful for weather queries"
        api_key: str = Field(default="demo-api-key", description="API key for weather service")

        def _run(self, city: str) -> str:
            """synchronous execution"""
            print(f"  ðŸ”§ tool used: WeatherTool._run(city='{city}')")
            # simulate weather API call
            weather_data = {
                "tokyo": "25Â°C, sunny",
                "london": "15Â°C, rainy",
                "paris": "20Â°C, cloudy",
            }
            weather = weather_data.get(city.lower(), "Weather data not available")
            return f"{city}: {weather}"

        async def _arun(self, city: str) -> str:
            """async execution"""
            return self._run(city)

    print("1. Custom tool class created:")
    weather_tool = WeatherTool()
    print(f"   â€¢ name: {weather_tool.name}")
    print(f"   â€¢ description: {weather_tool.description}")
    print(f"   â€¢ api_key: {weather_tool.api_key}")

    print("\n2. Direct tool execution:")
    result = weather_tool._run("Tokyo")
    print(f"   {result}")

    print("\n3. Using custom tool with agent:")
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    agent = create_agent(model=llm, tools=[weather_tool])

    query = "What's the weather in Paris?"
    result = agent.invoke({"messages": [HumanMessage(content=query)]})
    final_answer = result["messages"][-1].content
    print(f"   Query: {query}")
    print(f"   Answer: {final_answer}")

    print("\n4. BaseTool advantages:")
    print("   â€¢ State management (api_key)")
    print("   â€¢ Sync and async support")
    print("   â€¢ Complex initialization")
    print("   â€¢ Error handling hooks")


# endregion


# region Demo 5: Error Handling in Tools


def demo_error_handling() -> None:
    """
    demonstrate error handling in agent tools

    Error Handling Strategies:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              Tool Error Handling Patterns                   â”‚
    â”‚                                                             â”‚
    â”‚  Strategy 1: Graceful Degradation                           â”‚
    â”‚     @tool                                                   â”‚
    â”‚     def search(query: str) -> str:                          â”‚
    â”‚         try:                                                â”‚
    â”‚             return api_call(query)                          â”‚
    â”‚         except APIError:                                    â”‚
    â”‚             return "Search unavailable"                     â”‚
    â”‚                                                             â”‚
    â”‚  Strategy 2: Error Reporting                                â”‚
    â”‚     @tool                                                   â”‚
    â”‚     def search(query: str) -> str:                          â”‚
    â”‚         try:                                                â”‚
    â”‚             return api_call(query)                          â”‚
    â”‚         except APIError as e:                               â”‚
    â”‚             return f"Error: {str(e)}"                       â”‚
    â”‚                                                             â”‚
    â”‚  Strategy 3: Fallback Tools                                 â”‚
    â”‚     tools = [primary_search, backup_search]                 â”‚
    â”‚     # Agent tries primary, falls back to backup             â”‚
    â”‚                                                             â”‚
    â”‚  Strategy 4: Validation                                     â”‚
    â”‚     @tool                                                   â”‚
    â”‚     def divide(a: float, b: float) -> str:                  â”‚
    â”‚         if b == 0:                                          â”‚
    â”‚             return "Cannot divide by zero"                  â”‚
    â”‚         return str(a / b)                                   â”‚
    â”‚                                                             â”‚
    â”‚  âœ… Benefit: Agent continues despite tool failures          â”‚
    â”‚  âœ… Benefit: Clear error messages guide agent               â”‚
    â”‚  âš ï¸  Caution: Don't hide critical errors                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    print_section("Demo 5: Error Handling in Tools")

    # tool with error handling
    @tool
    def safe_divide(numerator: float, denominator: float) -> str:
        """divide two numbers with error handling"""
        print(f"  ðŸ”§ tool used: safe_divide(numerator={numerator}, denominator={denominator})")
        if denominator == 0:
            return "Error: Cannot divide by zero"
        try:
            result = numerator / denominator
            return str(result)
        except Exception as e:
            return f"Error: {str(e)}"

    print("1. Tool with error handling:")
    print(f"   â€¢ {safe_divide.name}: {safe_divide.description}")

    print("\n2. Testing error cases:")
    test_cases = [
        (10, 2, "Valid division"),
        (10, 0, "Division by zero"),
        (5, 0.5, "Valid division with float"),
    ]

    for num, den, desc in test_cases:
        result = safe_divide.invoke({"numerator": num, "denominator": den})
        print(f"   â€¢ {desc}: {num}/{den} = {result}")

    print("\n3. Using with agent:")
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    agent = create_agent(model=llm, tools=[safe_divide])

    queries = [
        "What is 100 divided by 5?",
        "What is 10 divided by 0?",
    ]

    for query in queries:
        print(f"\n   Query: {query}")
        result = agent.invoke({"messages": [HumanMessage(content=query)]})
        final_answer = result["messages"][-1].content
        print(f"   Answer: {final_answer}")

    print("\n4. Error handling best practices:")
    print("   â€¢ Validate inputs before execution")
    print("   â€¢ Return descriptive error messages")
    print("   â€¢ Don't crash the agent")
    print("   â€¢ Log errors for debugging")


# endregion


# region Demo 6: Web Search Agent


def demo_web_search_agent() -> None:
    """
    demonstrate agent with web search capability

    Web Search Agent Pattern:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         Agent with Real-World Information Access              â”‚
    â”‚                                                               â”‚
    â”‚  Pre-built Tool: DuckDuckGoSearchRun                          â”‚
    â”‚     from langchain_community.tools import DuckDuckGoSearchRun â”‚
    â”‚     search = DuckDuckGoSearchRun()                            â”‚
    â”‚                                                               â”‚
    â”‚  Agent Flow:                                                  â”‚
    â”‚     User: "What's the latest news about Python?"              â”‚
    â”‚       â†“                                                       â”‚
    â”‚     Agent: "I need current information"                       â”‚
    â”‚       â†“                                                       â”‚
    â”‚     Action: search("Python news 2024")                        â”‚
    â”‚       â†“                                                       â”‚
    â”‚     Observation: [search results]                             â”‚
    â”‚       â†“                                                       â”‚
    â”‚     Agent synthesizes answer from results                     â”‚
    â”‚                                                               â”‚
    â”‚  Use Cases:                                                   â”‚
    â”‚     â€¢ Current events and news                                 â”‚
    â”‚     â€¢ Real-time information                                   â”‚
    â”‚     â€¢ Fact-checking                                           â”‚
    â”‚     â€¢ Research and discovery                                  â”‚
    â”‚                                                               â”‚
    â”‚  âœ… Benefit: Access to current information                    â”‚
    â”‚  âœ… Benefit: Grounded in real data                            â”‚
    â”‚  âš ï¸  Caution: Search results may be noisy                     â”‚
    â”‚  âš ï¸  Caution: API rate limits apply                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    print_section("Demo 6: Web Search Agent")

    print("1. Creating web search tool...")
    search = DuckDuckGoSearchRun()
    print(f"   â€¢ Tool: {search.name}")
    print(f"   â€¢ Description: {search.description}")

    print("\n2. Creating agent with search capability...")
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    agent = create_agent(model=llm, tools=[search])

    print("\n3. Testing search queries:")
    queries = [
        "What is LangChain?",
        "What is the capital of France?",
    ]

    for query in queries:
        print(f"\n   Query: {query}")
        try:
            result = agent.invoke({"messages": [HumanMessage(content=query)]})
            final_answer = result["messages"][-1].content
            # truncate long answers
            if len(final_answer) > 200:
                final_answer = final_answer[:200] + "..."
            print(f"   Answer: {final_answer}")
        except Exception as e:
            print(f"   Error: {str(e)}")

    print("\n4. Web search agent insights:")
    print("   â€¢ Provides real-time information")
    print("   â€¢ Complements LLM's training data")
    print("   â€¢ Useful for current events")
    print("   â€¢ Rate limits may apply")


# endregion


# region Demo 7: Phase 4 Comparison


def demo_phase4_comparison() -> None:
    """
    compare Phase 4 custom agents with LangChain agents

    Phase 4 vs LangChain Comparison:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        Custom ReActAgent (Phase 4)                          â”‚
    â”‚                                                             â”‚
    â”‚  class ReActAgent:                                          â”‚
    â”‚      def __init__(self, registry: ToolRegistry):            â”‚
    â”‚          self.registry = registry                           â”‚
    â”‚          self.max_iterations = 5                            â”‚
    â”‚                                                             â”‚
    â”‚      def run(self, task: str) -> str:                       â”‚
    â”‚          for i in range(self.max_iterations):               â”‚
    â”‚              # 1. Generate thought and action               â”‚
    â”‚              response = self.llm.generate(prompt)           â”‚
    â”‚              thought, action, action_input = self.parse()   â”‚
    â”‚                                                             â”‚
    â”‚              # 2. Execute tool                              â”‚
    â”‚              tool = self.registry.get(action)               â”‚
    â”‚              observation = tool.execute(action_input)       â”‚
    â”‚                                                             â”‚
    â”‚              # 3. Check if done                             â”‚
    â”‚              if action == "Final Answer":                   â”‚
    â”‚                  return observation                         â”‚
    â”‚          return "Max iterations reached"                    â”‚
    â”‚                                                             â”‚
    â”‚  âœ… Learning: Full control, understand internals            â”‚
    â”‚  âŒ Production: Manual error handling, no streaming         â”‚
    â”‚                                                             â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚        LangChain / LangGraph Agent                          â”‚
    â”‚                                                             â”‚
    â”‚  @tool                                                      â”‚
    â”‚  def calculator(expr: str) -> str:                          â”‚
    â”‚      return str(eval(expr))                                 â”‚
    â”‚                                                             â”‚
    â”‚  agent = create_agent(                                      â”‚
    â”‚      model=ChatOpenAI(model="gpt-4o-mini"),                 â”‚
    â”‚      tools=[calculator]                                     â”‚
    â”‚  )                                                          â”‚
    â”‚  result = agent.invoke({                                    â”‚
    â”‚      "messages": [HumanMessage(content="2+2")]              â”‚
    â”‚  })                                                         â”‚
    â”‚                                                             â”‚
    â”‚  âœ… Production: Built-in features, robust, tested           â”‚
    â”‚  âœ… Concise: Less boilerplate code                          â”‚
    â”‚  âŒ Learning: Internal logic abstracted                     â”‚
    â”‚                                                             â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                When to Use Each                             â”‚
    â”‚                                                             â”‚
    â”‚  Phase 4 Custom:                                            â”‚
    â”‚    â€¢ Learning agent fundamentals                            â”‚
    â”‚    â€¢ Understanding ReAct pattern                            â”‚
    â”‚    â€¢ Prototyping new patterns                               â”‚
    â”‚    â€¢ Educational purposes                                   â”‚
    â”‚                                                             â”‚
    â”‚  LangChain / LangGraph:                                     â”‚
    â”‚    â€¢ Production applications                                â”‚
    â”‚    â€¢ Rapid development                                      â”‚
    â”‚    â€¢ Need advanced features                                 â”‚
    â”‚    â€¢ Standard use cases                                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """
    print_section("Demo 7: Phase 4 vs LangChain Comparison")

    print(cleandoc("""
        Your Phase 4 ReActAgent (Custom Implementation):
        ================================================

        class ReActAgent:
            def __init__(self, registry: ToolRegistry):
                self.registry = registry
                self.max_iterations = 5

            def run(self, task: str) -> str:
                for i in range(self.max_iterations):
                    # 1. Generate thought and action
                    response = self.llm.generate(prompt)
                    thought, action, action_input = self.parse(response)

                    # 2. Execute tool
                    tool = self.registry.get(action)
                    observation = tool.execute(action_input)

                    # 3. Check if done
                    if action == "Final Answer":
                        return observation

                return "Max iterations reached"

        âœ… Full control: Every step is explicit
        âœ… Learning: Understand agent internals
        âœ… Customization: Easy to modify logic
        âŒ Manual work: Error handling, retries, memory
        âŒ Missing: Streaming, async, advanced features
    """))

    print(cleandoc("""

        LangChain / LangGraph Agent (Framework):
        =========================================

        @tool
        def calculator(expr: str) -> str:
            return str(simple_eval(expr))  # safe: no code execution

        agent = create_agent(
            model=ChatOpenAI(model="gpt-4o-mini"),
            tools=[calculator]
        )
        result = agent.invoke({
            "messages": [HumanMessage(content="Calculate 2+2")]
        })

        âœ… Concise: ~10 lines of code
        âœ… Robust: Built-in error handling, retries
        âœ… Features: Streaming, async, memory, callbacks
        âœ… Production: Battle-tested, maintained
        âŒ Abstraction: Internal logic hidden
        âŒ Less control: Framework makes decisions
    """))

    print("\n\nWhen to Use Each:")
    print("-" * 70)
    print("\nPhase 4 Custom Agent:")
    print("  â€¢ Learning how agents work internally")
    print("  â€¢ Understanding ReAct pattern step-by-step")
    print("  â€¢ Prototyping new agent patterns")
    print("  â€¢ Educational and research purposes")

    print("\nLangChain / LangGraph Agent:")
    print("  â€¢ Production applications")
    print("  â€¢ Rapid development and deployment")
    print("  â€¢ Standard use cases and patterns")
    print("  â€¢ Need advanced features out-of-the-box")

    print("\n\nRecommendation:")
    print("-" * 70)
    print("  â€¢ Learn with Phase 4 custom implementation")
    print("  â€¢ Build with LangChain / LangGraph for production")
    print("  â€¢ Understand both to make informed choices")


# endregion



# region Demo Menu Configuration

DEMOS = [
    Demo("1", "Basic Tool Creation", "basic tool creation", demo_basic_tool_creation, needs_api=True),
    Demo("2", "Create Agent", "create agent", demo_create_agent, needs_api=True),
    Demo("3", "Multi-Tool Agent", "multi-tool agent", demo_multi_tool_agent, needs_api=True),
    Demo("4", "Custom Tool Class", "custom tool class", demo_custom_tool_class, needs_api=True),
    Demo("5", "Error Handling", "error handling", demo_error_handling, needs_api=True),
    Demo("6", "Web Search Agent", "web search agent", demo_web_search_agent, needs_api=True),
    Demo("7", "Phase 4 Comparison", "phase 4 comparison", demo_phase4_comparison, needs_api=True),
]

# endregion

def main() -> None:
    """run demonstrations with interactive menu"""
    has_openai, _ = check_api_keys()
    runner = MenuRunner(
        DEMOS,
        title="Agents & Tools - Practical Examples",
        subtitle="Using LangChain 1.0+ / LangGraph API",
        has_api=has_openai
    )
    runner.run()


if __name__ == "__main__":
    main()
